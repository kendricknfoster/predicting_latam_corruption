# Load requisite libraries. 

library(tidyverse)
library(readxl)
library(readr)
library(sf)
library(rstanarm)
library(rvest)
library(XML)
library(RCurl)
library(rlist)
library(janitor)
library(vdem)
library(rstanarm)

# I create a function to read in the various data generated by Transparency
# International for the Corruption Perceptions Index, including code to filter
# out countries in the Caribbean (choices explained in the About page). I also
# exclude the United States and Canada.

cpi_setup <- function(dataset, year, skip = 2, sheet = 1){
  read_excel(dataset, 
             skip = skip, 
             sheet = sheet) %>%
    filter(Region == "AME", 
           !(Country == "United States of America" | Country == "Canada" | Country == "Bahamas" | 
             Country == "Barbados" | Country == "Dominica" | Country == "Grenada" | Country == "Saint Lucia" | 
             Country == "Saint Vincent and the Grenadines" | Country == "Trinidad and Tobago")) %>%
    mutate(year = year) %>%
    clean_names()
}

# Details on choices to exclude 2019 detailed in the About Page. 

CPI2019 <- cpi_setup("raw_data/2019 CPI.xlsx", 
                     year = 2019) %>%
  rename(CPI = cpi_score_2019) %>%
  select(country, CPI, year)

CPI2018 <- cpi_setup("raw_data/2018 CPI.xlsx", 
                     year = 2018) %>%
  rename(CPI = cpi_score_2018) %>%
  select(country, CPI, year)

CPI2017 <- cpi_setup("raw_data/2017 CPI.xlsx",
                     year = 2017) %>%
  rename(CPI = cpi_score_2017) %>%
  select(country, CPI, year)

# The USA and Saint Vincent are spelled weirdly in the original dataset, so I
# filter them out separately here.

CPI2016 <- cpi_setup("raw_data/2016 CPI.xlsx", 
                     sheet = 3, 
                     skip = 0, 
                     year = 2016) %>%
  rename(CPI = cpi2016) %>%
  select(country, CPI, year) %>%
  filter(!(country == "The United States of America" | 
           country == "Saint Vincent and The Grenadines"))

# The original data doesn't include a regional qualifier, so I do the read_excel
# function separately here on the data page that actually does have all the data
# for the Americas.

CPI2015 <- read_excel("raw_data/2015 CPI.xlsx",
                      sheet = 2) %>%
  clean_names() %>%
  filter(!(country == "United States of America" | country == "Canada" | country == "Bahamas" | 
             country == "Barbados" | country == "Dominica" | country == "Grenada" | country == "Saint Lucia" | 
             country == "Saint Vincent and the Grenadines" | country == "Trinidad and Tobago")) %>%
  mutate(year = 2015) %>%
  rename(CPI = cpi_2015_score) %>%
  filter(!country == "United States") %>%
  select(country, CPI, year)

# 2014 and 2013 have different indicators for the Americas region (AM versus
# AME), but I edit these in the original dataset so I don't have to do weird
# code there. I exclude Puerto Rico because it's politically dependent (and an
# outlier in many other respects, including GDP).

CPI2014 <- cpi_setup("raw_data/2014 CPI.xlsx",
                     year = 2014, 
                     skip = 0) %>%
  filter(!(country == "United States" | country == "Puerto Rico")) %>%
  rename(CPI = cpi_2014) %>%
  select(country, CPI, year)

# For some crazy reason, CPI here was set as a character variable, so I mutate
# it to make sure it's numeric. I suppress errors since I don't particularly
# care about the various "Country Rank" columns in the end and don't want to
# deal with fixing them only to select them out in the end.

CPI2013 <- cpi_setup("raw_data/2013 CPI.xls",
                     year = 2013,
                     skip = 0) %>%
  rename(CPI = cpi_2013_score) %>%
  filter(!country == "United States",
         !country == "Puerto Rico")

CPI2013 <- CPI2013 %>%
  select(country, CPI, year) %>%
  mutate(CPI = as.numeric(CPI))

# I create one large dataset with all of the various CPI statistics for easier
# merging later on.

cpi_data <- bind_rows(CPI2013, CPI2014, CPI2015, CPI2016, CPI2017, CPI2018, CPI2019)

# I create a function here to clean up the World Bank data to only include Latin
# America and the Caribbean (since that's what I'm interested in) and pivot to
# create a tidy dataset. The World Bank dataset is only by country code in the
# data spreadsheet, so I load in the metadata so I can associate each country
# code with the respective country name.

clean_wb <- function(dataset, indicator){
  data <- read_excel(dataset, skip = 3) %>%
    clean_names()
  
  meta <- read_excel(dataset, sheet = 2) %>%
    clean_names()
  
  inner_join(data, meta, by = "country_code") %>%
    filter(region == "Latin America & Caribbean") %>%
    arrange(country_name) %>%
    rename(country = country_name) %>%
    select(country, x2013:x2019) %>%
    pivot_longer(cols = x2013:x2019,
                 names_to = "year",
                 values_to = indicator) %>%
    mutate(year = str_sub(year, 2, 5)) %>%
    mutate(year = as.numeric(year))
}

# I read in World Bank GDP per capita data. 

gdp_pc = clean_wb(dataset = "raw_data/GDP Per Capita.xls",
                  indicator = "GDP Per Capita")

# I read in World Bank Gini data on income inequality.  

gini = clean_wb(dataset = "raw_data/Gini.xls",
                indicator = "Gini")

# I read in World Bank data on government spending as a percentage of GDP. 

govt_spending = clean_wb(dataset = "raw_data/Government Spending.xls",
                         indicator = "Government Spending")

# I read in World Bank data on poverty. This particular spreadsheet has many
# different indicators in it, so I only filter to include the poverty rate
# indicator. I don't use the WB function here since I'm not sure how I can still
# filter by the indicator without messing everything up.

poverty_data = read_excel("raw_data/Poverty.xls", 
                          skip = 3) %>%
  clean_names() %>%
  filter(indicator_code == "SI.POV.DDAY")

poverty_meta = read_excel("raw_data/Poverty.xls", 
                          sheet = 2) %>%
  clean_names()

poverty <- inner_join(poverty_data, poverty_meta, by = "country_code") %>%
  filter(region == "Latin America & Caribbean") %>%
  rename(country = country_name) %>%
  select(country, x2013:x2019) %>%
  arrange(country) %>%
  pivot_longer(cols = x2013:x2019,
               names_to = "year",
               values_to = "Poverty Rate") %>%
  mutate(year = str_sub(year, 2, 5)) %>%
  mutate(year = as.numeric(year))

# I loaded in the vdem dataset with the vdem package, so I can now directly
# select the indicators I'm curious about with the extract_vdem function. I
# include the OSP so I can get the dataset using the original scale, not the
# normalized function. I now extract Bureaucratic Remuneration.

bureaucratic_remuneration <- extract_vdem(name_pattern = "v2strenadm",
                                          include_osp = TRUE) %>%
  select(vdem_country_name, year, v2strenadm_osp) %>%
  drop_na() %>%
  rename(country = vdem_country_name) %>%
  rename(`Bureaucratic Remuneration` = v2strenadm_osp) %>%
  filter(year >= 2013)

# I now extract Public Campaign Finance. 

public_finance <- extract_vdem(name_pattern = "v2elpubfin",
                               include_osp = TRUE) %>%
  select(vdem_country_name, year, v2elpubfin_osp) %>%
  drop_na() %>%
  rename(country = vdem_country_name) %>%
  rename(`Public Campaign Finance` = v2elpubfin_osp) %>%
  filter(year >= 2013)

# I read in INFRALATAM data on Infrastructure Spending as a % of GDP. The data
# is originally in Spanish, so I set the column names here and skip the original
# column names. I also fix the original dataset natively in Excel to change
# Spanish names for countries to English names for countries.

infrastructure_spending <- read_csv("raw_data/Infrastructure Spending.csv",
                                    col_names = c("country", "year", "type", "sector",
                                                  "subsector", "national_currency", 
                                                  "us_dollars", "gdp_percent"),
                                    cols(country = col_character(),
                                         year = col_double(),
                                         type = col_character(),
                                         sector = col_character(),
                                         subsector = col_character(),
                                         national_currency = col_number(),
                                         us_dollars = col_number(),
                                         gdp_percent = col_double()),
                                    skip = 1) %>%
  select(country, year, gdp_percent) %>%
  rename("Infrastructure Spending" = gdp_percent)

# I now join all the World Bank data together. I use an inner join since the
# data here is pretty much all the same.

wb_data <- inner_join(gdp_pc, gini, by = c("country", "year")) %>%
  inner_join(., govt_spending, by = c("country", "year")) %>%
  inner_join(., poverty, by = c("country", "year"))

# I now join the remainder of the data with the World Bank data. I use a left
# join to limit the dataset to the countries that I selected in the beginning
# with the CPI dataset.

final_data <- left_join(cpi_data, wb_data, by = c("country", "year")) %>%
  left_join(., bureaucratic_remuneration, by = c("country", "year")) %>%
  left_join(., public_finance, by = c("country", "year")) %>%
  left_join(., infrastructure_spending, by = c("country", "year"))

# I save the final data as a RDS to transfer it over to the Shiny App. 

saveRDS(final_data, file = "final_data.RDS")

# I read in the shapefile data. 

map <- st_read("raw_data/Shapefile") %>%
  rename("country" = "CNTRY_NAME")

# I merge the shapefile data with the map data so I can create my map in the
# Shiny App.

CPI_shapefile <- left_join(final_data, map, by = "country") %>%
  filter(year == 2019)

saveRDS(CPI_shapefile, file = "CPI_shapefile.RDS")