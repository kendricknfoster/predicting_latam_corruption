# Load requisite libraries. 

library(tidyverse)
library(readxl)
library(readr)
library(sf)
library(rstanarm)
library(rvest)
library(XML)
library(RCurl)
library(rlist)
library(janitor)
library(vdem)

# I create a function to read in the various data generated by Transparency
# International for the Corruption Perceptions Index, including code to filter
# out countries in the Caribbean (choices explained in the About page). I also
# exclude the United States and Canada.

cpi_setup <- function(dataset, year, skip = 2, sheet = 1){
  read_excel(dataset, 
             skip = skip, 
             sheet = sheet) %>%
    filter(Region == "AME", 
           !(Country == "United States of America" | Country == "Canada" | Country == "Bahamas" | 
             Country == "Barbados" | Country == "Dominica" | Country == "Puerto Rico" | 
             Country == "Grenada" | Country == "Jamaica" | Country == "Saint Lucia" | 
             Country == "Saint Vincent and the Grenadines" | Country == "Trinidad and Tobago")) %>%
    mutate(year = year) %>%
    clean_names()
}

CPI2019 <- cpi_setup("raw_data/2019 CPI.xlsx", 
                     year = 2019) %>%
  rename(CPI = cpi_score_2019) %>%
  select(country, CPI, year)

CPI2018 <- cpi_setup("raw_data/2018 CPI.xlsx", 
                     year = 2018) %>%
  rename(CPI = cpi_score_2018) %>%
  select(country, CPI, year)

CPI2017 <- cpi_setup("raw_data/2017 CPI.xlsx",
                     year = 2017) %>%
  rename(CPI = cpi_score_2017) %>%
  select(country, CPI, year)

# The USA and Saint Vincent are spelled weirdly in the original dataset, so I
# filter them out separately here.

CPI2016 <- cpi_setup("raw_data/2016 CPI.xlsx", 
                     sheet = 3, 
                     skip = 0, 
                     year = 2016) %>%
  rename(CPI = cpi2016) %>%
  select(country, CPI, year) %>%
  filter(!(country == "The United States of America" | 
           country == "Saint Vincent and The Grenadines"))

# The original data doesn't include a regional qualifier, so I do the read_excel
# function separately here on the data page that actually does have all the data
# for the Americas.

CPI2015 <- read_excel("raw_data/2015 CPI.xlsx",
                      sheet = 2) %>%
  clean_names() %>%
  filter(!(country == "United States" | country == "Canada" | country == "Bahamas" | 
             country == "Barbados" | country == "Dominica" | country == "Grenada" | country == "Saint Lucia" | 
             country == "Saint Vincent and the Grenadines" | country == "Trinidad and Tobago")) %>%
  mutate(year = 2015) %>%
  rename(CPI = cpi_2015_score) %>%
  select(country, CPI, year)

# 2014 and 2013 have different indicators for the Americas region (AM versus
# AME), but I edit these in the original dataset so I don't have to do weird
# code there. I exclude Puerto Rico because it's politically dependent (and an
# outlier in many other respects, including GDP).

CPI2014 <- cpi_setup("raw_data/2014 CPI.xlsx",
                     year = 2014, 
                     skip = 0) %>%
  filter(!(country == "United States")) %>%
  rename(CPI = cpi_2014) %>%
  select(country, CPI, year)

# For some crazy reason, CPI here was set as a character variable, so I mutate
# it to make sure it's numeric. I suppress errors since I don't particularly
# care about the various "Country Rank" columns in the end and don't want to
# deal with fixing them only to select them out in the end.

CPI2013 <- cpi_setup("raw_data/2013 CPI.xls",
                     year = 2013,
                     skip = 0) %>%
  rename(CPI = cpi_2013_score) %>%
  filter(!country == "United States",
         !country == "Puerto Rico")

CPI2013 <- CPI2013 %>%
  select(country, CPI, year) %>%
  mutate(CPI = as.numeric(CPI))

# This particular spreadsheet kept producing an error when I ran the function,
# so I just copied out the original source doe and it worked fine.

CPI2012 <- read_excel("raw_data/2012 CPI.xlsx") %>%
  clean_names() %>%
  filter(!(country == "United States" | country == "Canada" | country == "Bahamas" | 
             country == "Barbados" | country == "Dominica" | country == "Grenada" | 
             country == "Saint Lucia" | country == "Saint Vincent and the Grenadines" | 
             country == "Trinidad and Tobago" | country == "Puerto Rico")) %>%
  mutate(year = 2012) %>%
  rename(CPI = cpi_2012_score) %>%
  select(country, CPI, year)

# I make slight modifications to the function to adapt it to CSV formats. These
# are older datasets when the scores were out of 10 instead of 100, so I
# multiply the columns by 10 to account for this.

cpi_setup_csv <- cpi_setup <- function(dataset, year, skip = 0){
  read_csv(dataset, 
           skip = skip, 
           col_types = cols(country = col_character(), 
                            iso = col_character(),
                            region = col_character(),
                            score = col_double(), 
                            rank = col_double(),
                            interval = col_character())) %>%
    filter(region == "AME",
           !(country == "United States" | country == "Canada" | country == "Bahamas" | 
               country == "Jamaica" | country == "Barbados" | country == "Dominica" | 
               country == "Grenada" | country == "Saint Lucia" | country == "Puerto Rico" |
               country == "Saint Vincent and the Grenadines" | country == "USA" | 
               country == "Trinidad and Tobago" | country == "Swaziland")) %>%
    mutate(year = year) %>%
    mutate(score = score * 10) %>%
    clean_names()
}

# I input the data from the CSVs from 2001 to 2011 using the second function
# that I elaborated.

CPI2011 <- cpi_setup_csv("raw_data/2011 CPI.csv",
                     year = 2011) %>%
  rename(CPI = score) %>%
  select(country, CPI, year)

CPI2010 <- cpi_setup_csv("raw_data/2010 CPI.csv",
                         year = 2010) %>%
  rename(CPI = score) %>%
  select(country, CPI, year)

CPI2009 <- cpi_setup_csv("raw_data/2009 CPI.csv",
                         year = 2009) %>%
  filter(!country == "Slovenia") %>%
  rename(CPI = score) %>%
  select(country, CPI, year)

CPI2008 <- cpi_setup_csv("raw_data/2008 CPI.csv",
                         year = 2008) %>%
  filter(!(country == "United States of America")) %>%
  rename(CPI = score) %>%
  select(country, CPI, year)

CPI2007 <- cpi_setup_csv("raw_data/2007 CPI.csv",
                         year = 2007) %>%
  rename(CPI = score) %>%
  select(country, CPI, year)

CPI2006 <- cpi_setup_csv("raw_data/2006 CPI.csv",
                         year = 2006) %>%
  rename(CPI = score) %>%
  select(country, CPI, year)

CPI2005 <- cpi_setup_csv("raw_data/2005 CPI.csv",
                         year = 2005) %>%
  rename(CPI = score) %>%
  select(country, CPI, year)

CPI2004 <- cpi_setup_csv("raw_data/2004 CPI.csv",
                         year = 2004) %>%
  rename(CPI = score) %>%
  select(country, CPI, year) %>%
  filter(!(country == "Benin" | country == "Cote d'Ivoire"))

CPI2003 <- cpi_setup_csv("raw_data/2003 CPI.csv",
                         year = 2003) %>%
  rename(CPI = score) %>%
  select(country, CPI, year) %>%
  filter(!country == "Cyprus")

CPI2002 <- cpi_setup_csv("raw_data/2002 CPI.csv",
                         year = 2002) %>%
  rename(CPI = score) %>%
  select(country, CPI, year) %>%
  filter(!country == "Trinidad & Tobago")

CPI2001 <- cpi_setup_csv("raw_data/2001 CPI.csv",
                         year = 2001) %>%
  rename(CPI = score) %>%
  select(country, CPI, year) %>%
  mutate(country = if_else(country == "Dominican Rep", "Dominican Republic", country))

# I create one large dataset with all of the various CPI statistics for easier
# merging later on. I also invert the CPI dataset so the indicator represents
# the presence of corruption, not the absence of corruption (see more about the
# data sources in the Shiny App).

cpi_data <- bind_rows(CPI2001, CPI2002, CPI2003, CPI2004, CPI2005,
                      CPI2006, CPI2007, CPI2008, CPI2009, CPI2010, 
                      CPI2011, CPI2012, CPI2013, CPI2014, CPI2015, 
                      CPI2016, CPI2017, CPI2018, CPI2019) %>%
  mutate(CPI = 100 - CPI)

# I create a function here to clean up the World Bank data to only include Latin
# America and the Caribbean (since that's what I'm interested in) and pivot to
# create a tidy dataset. The World Bank dataset is only by country code in the
# data spreadsheet, so I load in the metadata so I can associate each country
# code with the respective country name.

clean_wb <- function(dataset, indicator){
  data <- read_excel(dataset, skip = 3) %>%
    clean_names()
  
  meta <- read_excel(dataset, sheet = 2) %>%
    clean_names()
  
  inner_join(data, meta, by = "country_code") %>%
    filter(region == "Latin America & Caribbean") %>%
    arrange(country_name) %>%
    rename(country = country_name) %>%
    select(country, x2001:x2019) %>%
    pivot_longer(cols = x2001:x2019,
                 names_to = "year",
                 values_to = indicator) %>%
    mutate(year = str_sub(year, 2, 5)) %>%
    mutate(year = as.numeric(year))
}

# I read in World Bank GDP per capita data. 

gdp_pc = clean_wb(dataset = "raw_data/GDP Per Capita.xls",
                  indicator = "gdp_pc")

# I read in World Bank Gini data on income inequality.  

gini = clean_wb(dataset = "raw_data/Gini.xls",
                indicator = "gini")

# I read in World Bank data on government spending as a percentage of GDP. 

govt_spending = clean_wb(dataset = "raw_data/Government Spending.xls",
                         indicator = "govt_spending")

# I read in World Bank data on poverty. This particular spreadsheet has many
# different indicators in it, so I only filter to include the poverty rate
# indicator. I don't use the WB function here since I'm not sure how I can still
# filter by the indicator without messing everything up.

poverty_data = read_excel("raw_data/Poverty.xls", 
                          skip = 3) %>%
  clean_names() %>%
  filter(indicator_code == "SI.POV.DDAY")

poverty_meta = read_excel("raw_data/Poverty.xls", 
                          sheet = 2) %>%
  clean_names()

poverty <- inner_join(poverty_data, poverty_meta, by = "country_code") %>%
  filter(region == "Latin America & Caribbean") %>%
  rename(country = country_name) %>%
  select(country, x2001:x2019) %>%
  arrange(country) %>%
  pivot_longer(cols = x2001:x2019,
               names_to = "year",
               values_to = "poverty_rate") %>%
  mutate(year = str_sub(year, 2, 5)) %>%
  mutate(year = as.numeric(year))

# I loaded in the vdem dataset with the vdem package, so I can now directly
# select the indicators I'm curious about with the extract_vdem function. I
# include the OSP so I can get the dataset using the original scale, not the
# normalized function. I now extract Bureaucratic Remuneration.

bureaucratic_remuneration <- extract_vdem(name_pattern = "v2strenadm",
                                          include_osp = TRUE) %>%
  select(vdem_country_name, year, v2strenadm_osp) %>%
  drop_na() %>%
  rename(country = vdem_country_name) %>%
  rename(bur_rem = v2strenadm_osp) %>%
  filter(year >= 2001)

# I now extract Public Campaign Finance. 

public_finance <- extract_vdem(name_pattern = "v2elpubfin",
                               include_osp = TRUE) %>%
  select(vdem_country_name, year, v2elpubfin_osp) %>%
  drop_na() %>%
  rename(country = vdem_country_name) %>%
  rename(pcf = v2elpubfin_osp) %>%
  filter(year >= 2001)

# I now extract Property Rights. 

property_rights <- extract_vdem(name_pattern = "v2xcl_prpty") %>%
  select(vdem_country_name, year, v2xcl_prpty) %>%
  drop_na() %>%
  rename(country = vdem_country_name) %>%
  rename(prop_rights = v2xcl_prpty) %>%
  filter(year >= 2001)

# I read in INFRALATAM data on Infrastructure Spending as a % of GDP. The data
# is originally in Spanish, so I set the column names here and skip the original
# column names. I also fix the original dataset natively in Excel to change
# Spanish names for countries to English names for countries.

infrastructure_spending <- read_csv("raw_data/Infrastructure Spending.csv",
                                    col_names = c("country", "year", "type", "sector",
                                                  "subsector", "national_currency", 
                                                  "us_dollars", "gdp_percent"),
                                    cols(country = col_character(),
                                         year = col_double(),
                                         type = col_character(),
                                         sector = col_character(),
                                         subsector = col_character(),
                                         national_currency = col_number(),
                                         us_dollars = col_number(),
                                         gdp_percent = col_double()),
                                    skip = 1) %>%
  select(country, year, gdp_percent) %>%
  rename(infra_spend = gdp_percent)

# I now join all the World Bank data together. I use an inner join since the
# data here is pretty much all the same.

wb_data <- inner_join(gdp_pc, gini, by = c("country", "year")) %>%
  inner_join(., govt_spending, by = c("country", "year")) %>%
  inner_join(., poverty, by = c("country", "year"))

# I now join the remainder of the data with the World Bank data. I use a left
# join to limit the dataset to the countries that I selected in the beginning
# with the CPI dataset.

final_data <- left_join(cpi_data, wb_data, by = c("country", "year")) %>%
  left_join(., bureaucratic_remuneration, by = c("country", "year")) %>%
  left_join(., public_finance, by = c("country", "year")) %>%
  left_join(., property_rights, by = c("country", "year")) %>%
  left_join(., infrastructure_spending, by = c("country", "year"))

# I mutate a column with the log of GDP per capita in order to test it in
# regressions later on.

final_data <- final_data %>%
  mutate(log_gdp = log10(gdp_pc))
  
# I save the final data as a RDS to transfer it over to the Shiny App. 

saveRDS(final_data, file = "final_data.RDS")

# I read in the shapefile data. 

map <- st_read("raw_data/Shapefile") %>%
  rename("country" = "CNTRY_NAME")

# I merge the shapefile data with the map data so I can create my map in the
# Shiny App.

CPI_shapefile <- left_join(final_data, map, by = "country") %>%
  filter(year == 2019) %>%
  st_as_sf()

saveRDS(CPI_shapefile, file = "CPI_shapefile.RDS")